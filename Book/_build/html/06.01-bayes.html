

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>18. Bayesian Statistics &#8212; Learning Statistics with Python</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '06.01-bayes';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="19. Epilogue" href="06.02-epilogue.html" />
    <link rel="prev" title="17. Factorial ANOVA" href="05.05-anova2.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="landingpage.html">
  
  
  
  
  
    <p class="title logo__title">Learning Statistics with Python</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="landingpage.html">
                    Learning Statistics with Python
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I. Background</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01.01-intro.html">1. Why do we learn statistics?</a></li>
<li class="toctree-l1"><a class="reference internal" href="01.02-studydesign.html">2. A brief introduction to research design</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II. An Introduction to Python</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="02.01-getting_started_with_python.html">3. Getting Started with Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="02.02-more_python_concepts.html">4. More Python Concepts</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III. Working With Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="03.01-descriptives.html">5. Descriptive statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="03.02-drawing_graphs.html">6. Drawing Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="03.03-pragmatic_matters.html">7. Data Wrangling</a></li>
<li class="toctree-l1"><a class="reference internal" href="03.04-basic_programming.html">8. Basic Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV. Statistical Theory</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="04.01-intro-to-probability.html">9. Statistical theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="04.02-probability.html">10. Introduction to Probability</a></li>
<li class="toctree-l1"><a class="reference internal" href="04.03-estimation.html">11. Estimating unknown quantities from a sample</a></li>
<li class="toctree-l1"><a class="reference internal" href="04.04-hypothesis-testing.html">12. Hypothesis Testing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V. Statistical Tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="05.01-chisquare.html">13. Categorical data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.02-ttest.html">14. Comparing Two Means</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.03-anova.html">15. Comparing several means (one-way ANOVA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.04-regression.html">16. Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="05.05-anova2.html">17. Factorial ANOVA</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part VI. Endings, Alternatives and Prospects</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">18. Bayesian Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="06.02-epilogue.html">19. Epilogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">20. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ethanweed/pythonbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ethanweed/pythonbook/issues/new?title=Issue%20on%20page%20%2F06.01-bayes.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/06.01-bayes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayesian Statistics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-reasoning-by-rational-agents">18.1. Probabilistic reasoning by rational agents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#priors-what-you-believed-before">18.1.1. Priors: what you believed before</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihoods-theories-about-the-data">18.1.2. Likelihoods: theories about the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-joint-probability-of-data-and-hypothesis">18.1.3. The joint probability of data and hypothesis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#updating-beliefs-using-bayes-rule">18.1.4. Updating beliefs using Bayes’ rule</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-hypothesis-tests">18.2. Bayesian hypothesis tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayes-factor">18.2.1. The Bayes factor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-bayes-factors">18.2.2. Interpreting Bayes factors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-be-a-bayesian">18.3. Why be a Bayesian?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-that-mean-what-you-think-they-mean">18.3.1. Statistics that mean what you think they mean</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evidentiary-standards-you-can-believe">18.4. Evidentiary standards you can believe</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-it-really-this-bad">18.4.1. Is it really this bad?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-analysis-of-contingency-tables">18.5. Bayesian analysis of contingency tables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orthodox-text">18.5.1. The orthodox text</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-test">18.5.2. The Bayesian test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-up-the-results">18.5.3. Writing up the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-sampling-plans">18.5.4. Other sampling plans</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-t-tests">18.6. Bayesian <span class="math notranslate nohighlight">\(t\)</span>-tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">18.6.1. Independent samples <span class="math notranslate nohighlight">\(t\)</span>-test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-samples-t-test">18.6.2. Paired samples <span class="math notranslate nohighlight">\(t\)</span>-test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-regression">18.7. Bayesian regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-quick-refresher">18.7.1. A quick refresher</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-version">18.7.2. The Bayesian version</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-the-best-model">18.7.3. Finding the best model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-bayes-factors-for-all-included-terms">18.7.4. Extracting Bayes factors for all included terms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-anova">18.8. Bayesian ANOVA</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">18.8.1. A quick refresher</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">18.8.2. The Bayesian version</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-bayesian-type-ii-tests">18.8.3. Constructing Bayesian Type II tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">18.9. Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-statistics">
<span id="bayes"></span><h1><span class="section-number">18. </span>Bayesian Statistics<a class="headerlink" href="#bayesian-statistics" title="Permalink to this heading">#</a></h1>
<blockquote>
<div><p><em>In our reasonings concerning matter of fact, there are all imaginable degrees of assurance, from the highest certainty to the lowest species of moral evidence. A wise man, therefore, proportions his belief to the evidence.</em>
– <a class="reference external" href="http://en.wikiquote.org/wiki/David_Hume">David Hume</a>.</p>
</div></blockquote>
<p>The ideas I’ve presented to you in this book describe inferential statistics from the frequentist perspective. I’m not alone in doing this. In fact, almost every textbook given to undergraduate psychology students presents the opinions of the frequentist statistician as <em>the</em> theory of inferential statistics, the one true way to do things. I have taught this way for practical reasons. The frequentist view of statistics dominated the academic field of statistics for most of the 20th century, and this dominance is even more extreme among applied scientists. It was and is current practice among psychologists to use frequentist methods, although this is changing. Because frequentist methods are ubiquitous in scientific papers, every student of statistics needs to understand those methods, otherwise they will be unable to make sense of what those papers are saying! Unfortunately – in my opinion at least – the current practice in psychology is often misguided, and the reliance on frequentist methods is partly to blame. In this chapter I explain why I think this, and provide an introduction to Bayesian statistics, an approach that I think is generally superior to the orthodox approach.</p>
<p>This chapter comes in two parts. First I talk about <a class="reference internal" href="#basicbayes"><span class="std std-ref">what Bayesian statistics are all about</span></a>, covering the basic mathematical rules for how it works as well as an explanation for <a class="reference internal" href="#whybayes"><span class="std std-ref">why I think the Bayesian approach is so useful</span></a>. Afterwards, I provide a brief overview of how you can do Bayesian versions of <a class="reference internal" href="#bayescontingency"><span class="std std-ref">chi-square tests</span></a>, <a class="reference internal" href="#ttestbf"><span class="std std-ref"><span class="math notranslate nohighlight">\(t\)</span>-tests</span></a>, <a class="reference internal" href="#bayesregression"><span class="std std-ref">regression</span></a>) and <a class="reference internal" href="#bayesanova"><span class="std std-ref">ANOVA</span></a>.</p>
<section id="probabilistic-reasoning-by-rational-agents">
<span id="basicbayes"></span><h2><span class="section-number">18.1. </span>Probabilistic reasoning by rational agents<a class="headerlink" href="#probabilistic-reasoning-by-rational-agents" title="Permalink to this heading">#</a></h2>
<p>From a Bayesian perspective, statistical inference is all about <em>belief revision</em>. I start out with a set of candidate hypotheses <span class="math notranslate nohighlight">\(h\)</span> about the world. I don’t know which of these hypotheses is true, but I <em>do</em> have some beliefs about which hypotheses are plausible and which are not. When I observe the data <span class="math notranslate nohighlight">\(d\)</span>, I have to revise those beliefs. If the data are consistent with a hypothesis, my belief in that hypothesis is strengthened. If the data inconsistent with the hypothesis, my belief in that hypothesis is weakened. That’s it! At the end of this section I’ll give a precise description of how Bayesian reasoning works, but first I want to work through a simple example in order to introduce the key ideas. Consider the following reasoning problem:</p>
<blockquote>
<div><p><em>I’m carrying an umbrella. Do you think it will rain?</em></p>
</div></blockquote>
<p>In this problem, I have presented you with a single piece of data (<span class="math notranslate nohighlight">\(d =\)</span> I’m carrying the umbrella), and I’m asking you to tell me your beliefs about whether it’s raining. You have two possible <strong><em>hypotheses</em></strong>, <span class="math notranslate nohighlight">\(h\)</span>: either it rains today or it does not. How should you solve this problem?</p>
<section id="priors-what-you-believed-before">
<span id="priors"></span><h3><span class="section-number">18.1.1. </span>Priors: what you believed before<a class="headerlink" href="#priors-what-you-believed-before" title="Permalink to this heading">#</a></h3>
<p>The first thing you need to do ignore what I told you about the umbrella, and write down your pre-existing beliefs about rain. This is important: if you want to be honest about how your beliefs have been revised in the light of new evidence, then you <em>must</em> say something about what you believed before those data appeared! So, what might you believe about whether it will rain today? You probably know that I live in Australia, and that much of Australia is hot and dry. And in fact you’re right: the city of Adelaide where I live has a Mediterranean climate, very similar to southern California, southern Europe or northern Africa. I’m writing this in January, and so you can assume it’s the middle of summer. In fact, you might have decided to take a quick look on Wikipedia<a class="footnote-reference brackets" href="#adelaide" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> and discovered that Adelaide gets an average of 4.4 days of rain across the 31 days of January. Without knowing anything else, you might conclude that the probability of January rain in Adelaide is about 15%, and the probability of a dry day is 85%. If this is really what you believe about Adelaide rainfall (and now that I’ve told it to you, I’m betting that this really <em>is</em> what you believe) then what I have written here is your <strong><em>prior distribution</em></strong>, written <span class="math notranslate nohighlight">\(P(h)\)</span>:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Hypothesis</p></th>
<th class="head"><p>Degree of Belief</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy day</p></td>
<td><p>0.15</p></td>
</tr>
<tr class="row-odd"><td><p>Dry day</p></td>
<td><p>0.85</p></td>
</tr>
</tbody>
</table>
</section>
<section id="likelihoods-theories-about-the-data">
<h3><span class="section-number">18.1.2. </span>Likelihoods: theories about the data<a class="headerlink" href="#likelihoods-theories-about-the-data" title="Permalink to this heading">#</a></h3>
<p>To solve the reasoning problem, you need a theory about my behaviour. When does Dan carry an umbrella? You might guess that I’m not a complete idiot<a class="footnote-reference brackets" href="#idiot" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>, and I try to carry umbrellas only on rainy days. On the other hand, you also know that I have young kids, and you wouldn’t be all that surprised to know that I’m pretty forgetful about this sort of thing. Let’s suppose that on rainy days I remember my umbrella about 30% of the time (I really am awful at this). But let’s say that on dry days I’m only about 5% likely to be carrying an umbrella. So you might write out a little table like this:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Hypothesis</p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No umbrella</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy day</p></td>
<td><p>0.30</p></td>
<td><p>0.70</p></td>
</tr>
<tr class="row-odd"><td><p>Dry day</p></td>
<td><p>0.05</p></td>
<td><p>0.95</p></td>
</tr>
</tbody>
</table>
<p>It’s important to remember that each cell in this table describes your beliefs about what data <span class="math notranslate nohighlight">\(d\)</span> will be observed, <em>given</em> the truth of a particular hypothesis <span class="math notranslate nohighlight">\(h\)</span>. This “conditional probability” is written <span class="math notranslate nohighlight">\(P(d|h)\)</span>, which you can read as “the probability of <span class="math notranslate nohighlight">\(d\)</span> given <span class="math notranslate nohighlight">\(h\)</span>”. In Bayesian statistics, this is referred to as <strong><em>likelihood</em></strong> of data <span class="math notranslate nohighlight">\(d\)</span> given hypothesis <span class="math notranslate nohighlight">\(h\)</span>.<a class="footnote-reference brackets" href="#likelihood" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p>
</section>
<section id="the-joint-probability-of-data-and-hypothesis">
<h3><span class="section-number">18.1.3. </span>The joint probability of data and hypothesis<a class="headerlink" href="#the-joint-probability-of-data-and-hypothesis" title="Permalink to this heading">#</a></h3>
<p>At this point, all the elements are in place. Having written down the priors and the likelihood, you have all the information you need to do Bayesian reasoning. The question now becomes, <em>how</em> do we use this information? As it turns out, there’s a very simple equation that we can use here, but it’s important that you understand why we use it, so I’m going to try to build it up from more basic ideas.</p>
<p>Let’s start out with one of the rules of probability theory. I listed it in a table way back in the chapter on <a class="reference internal" href="04.02-probability.html#basicprobability"><span class="std std-ref">probability</span></a>, but I didn’t make a big deal out of it at the time and you probably ignored it. The rule in question is the one that talks about the probability that <em>two</em> things are true. In our example, you might want to calculate the probability that today is rainy (i.e., hypothesis <span class="math notranslate nohighlight">\(h\)</span> is true) <em>and</em> I’m carrying an umbrella (i.e., data <span class="math notranslate nohighlight">\(d\)</span> is observed). The <strong><em>joint probability</em></strong> of the hypothesis and the data is written <span class="math notranslate nohighlight">\(P(d,h)\)</span>, and you can calculate it by multiplying the prior <span class="math notranslate nohighlight">\(P(h)\)</span> by the likelihood <span class="math notranslate nohighlight">\(P(d|h)\)</span>. Mathematically, we say that:</p>
<div class="math notranslate nohighlight">
\[
P(d,h) = P(d|h) P(h)
\]</div>
<p>So, what is the probability that today is a rainy day <em>and</em> I remember to carry an umbrella? As we discussed earlier, the prior tells us that the probability of a rainy day is 15%, and the likelihood tells us that the probability of me remembering my umbrella on a rainy day is 30%. So the probability that both of these things are true is calculated by multiplying the two:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(\mbox{rainy}, \mbox{umbrella}) &amp; = &amp; P(\mbox{umbrella} | \mbox{rainy}) \times  P(\mbox{rainy}) \\
&amp; = &amp; 0.30 \times 0.15 \\
&amp; = &amp; 0.045
\end{align}
\end{split}\]</div>
<p>In other words, <em>before being told anything about what actually happened</em>, you think that there is a 4.5% probability that today will be a rainy day and that I will remember an umbrella. However, there are of course <em>four</em> possible things that could happen, right? So let’s repeat the exercise for all four. If we do that, we end up with the following table:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No-umbrella</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy</p></td>
<td><p>0.045</p></td>
<td><p>0.105</p></td>
</tr>
<tr class="row-odd"><td><p>Dry</p></td>
<td><p>0.0425</p></td>
<td><p>0.8075</p></td>
</tr>
</tbody>
</table>
<p>This table captures all the information about which of the four possibilities are likely. To really get the full picture, though, it helps to add the row totals and column totals. That gives us this table:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No-umbrella</p></th>
<th class="head"><p>Total</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy</p></td>
<td><p>0.0450</p></td>
<td><p>0.1050</p></td>
<td><p>0.15</p></td>
</tr>
<tr class="row-odd"><td><p>Dry</p></td>
<td><p>0.0425</p></td>
<td><p>0.8075</p></td>
<td><p>0.85</p></td>
</tr>
<tr class="row-even"><td><p>Total</p></td>
<td><p>0.0875</p></td>
<td><p>0.9125</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>This is a very useful table, so it’s worth taking a moment to think about what all these numbers are telling us. First, notice that the row sums aren’t telling us anything new at all. For example, the first row tells us that if we ignore all this umbrella business, the chance that today will be a rainy day is 15%. That’s not surprising, of course: that’s our prior. The important thing isn’t the number itself: rather, the important thing is that it gives us some confidence that our calculations are sensible! Now take a look at the column sums, and notice that they tell us something that we haven’t explicitly stated yet. In the same way that the row sums tell us the probability of rain, the column sums tell us the probability of me carrying an umbrella. Specifically, the first column tells us that on average (i.e., ignoring whether it’s a rainy day or not), the probability of me carrying an umbrella is 8.75%. Finally, notice that when we sum across all four logically-possible events, everything adds up to 1. In other words, what we have written down is a proper probability distribution defined over all possible combinations of data and hypothesis.</p>
<p>Now, because this table is so useful, I want to make sure you understand what all the elements correspond to, and how they written:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No-umbrella</p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(Umbrella, Rainy)</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(No-umbrella, Rainy)</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(Rainy)</p></td>
</tr>
<tr class="row-odd"><td><p>Dry</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(Umbrella, Dry)</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(No-umbrella, Dry)</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(Dry)</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(Umbrella)</p></td>
<td><p><span class="math notranslate nohighlight">\(P\)</span>(No-umbrella)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<p>Finally, let’s use “proper” statistical notation. In the rainy day problem, the data corresponds to the observation that I do or do not have an umbrella. So we’ll let <span class="math notranslate nohighlight">\(d_1\)</span> refer to the possibility that you observe me carrying an umbrella, and <span class="math notranslate nohighlight">\(d_2\)</span> refers to you observing me not carrying one. Similarly, <span class="math notranslate nohighlight">\(h_1\)</span> is your hypothesis that today is rainy, and <span class="math notranslate nohighlight">\(h_2\)</span> is the hypothesis that it is not. Using this notation, the table looks like this:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>d1</p></th>
<th class="head"><p>d2</p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(h_1\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_1,d_1)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_1,d_2)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_1)\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(h_2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_2,d_1)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_2,d_2)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(h_2)\)</span></p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p><span class="math notranslate nohighlight">\(P(d_1)\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(P(d_2)\)</span></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="updating-beliefs-using-bayes-rule">
<h3><span class="section-number">18.1.4. </span>Updating beliefs using Bayes’ rule<a class="headerlink" href="#updating-beliefs-using-bayes-rule" title="Permalink to this heading">#</a></h3>
<p>The table we laid out in the last section is a very powerful tool for solving the rainy day problem, because it considers all four logical possibilities and states exactly how confident you are in each of them <em>before being given any data</em>. It’s now time to consider what happens to our beliefs when we are actually given the data. In the rainy day problem, you are told that I really <em>am</em> carrying an umbrella. This is something of a surprising event: according to our table, the probability of me carrying an umbrella is only 8.75%. But that makes sense, right? A person carrying an umbrella on a summer day in a hot dry city is pretty unusual, and so you really weren’t expecting that. Nevertheless, the problem tells you that it is true. No matter how unlikely you thought it was, you must now adjust your beliefs to accommodate the fact that you now <em>know</em> that I have an umbrella.<a class="footnote-reference brackets" href="#umbrella" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a> To reflect this new knowledge, our <em>revised</em> table must have the following numbers:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No-umbrella</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy</p></td>
<td><p></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Dry</p></td>
<td><p></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>Total</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>In other words, the facts have eliminated any possibility of “no umbrella”, so we have to put zeros into any cell in the table that implies that I’m not carrying an umbrella. Also, because you know for a fact that I am carrying an umbrella, so the column sum on the left must be 1 to correctly describe the fact that <span class="math notranslate nohighlight">\(P(\mbox{umbrella})=1\)</span>.</p>
<p>What two numbers should we put in the empty cells? Again, let’s not worry about the maths, and instead think about our intuitions. When we wrote out our table the first time, it turned out that those two cells had almost identical numbers, right? We worked out that the joint probability of “rain and umbrella” was 4.5%, and the joint probability of “dry and umbrella” was 4.25%. In other words, before I told you that I am in fact carrying an umbrella, you’d have said that these two events were almost identical in probability, yes? But notice that <em>both</em> of these possibilities are consistent with the fact that I actually am carrying an umbrella. From the perspective of these two possibilities, very little has changed. I hope you’d agree that it’s <em>still</em> true that these two possibilities are equally plausible. So what we expect to see in our final table is some numbers that preserve the fact that “rain and umbrella” is <em>slightly</em> more plausible than “dry and umbrella”, while still ensuring that numbers in the table add up. Something like this, perhaps?</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Umbrella</p></th>
<th class="head"><p>No-umbrella</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Rainy</p></td>
<td><p>0.514</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Dry</p></td>
<td><p>0.486</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>Total</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>What this table is telling you is that, after being told that I’m carrying an umbrella, you believe that there’s a 51.4% chance that today will be a rainy day, and a 48.6% chance that it won’t. That’s the answer to our problem! The <strong><em>posterior probability</em></strong> of rain <span class="math notranslate nohighlight">\(P(h|d)\)</span> given that I am carrying an umbrella is 51.4%</p>
<p>How did I calculate these numbers? You can probably guess. To work out that there was a 0.514 probability of “rain”, all I did was take the 0.045 probability of “rain and umbrella” and divide it by the 0.0875 chance of “umbrella”. This produces a table that satisfies our need to have everything sum to 1, and our need not to interfere with the relative plausibility of the two events that are actually consistent with the data. To say the same thing using fancy statistical jargon, what I’ve done here is divide the joint probability of the hypothesis and the data <span class="math notranslate nohighlight">\(P(d,h)\)</span> by the <strong><em>marginal probability</em></strong> of the data <span class="math notranslate nohighlight">\(P(d)\)</span>, and this is what gives us the posterior probability of the hypothesis <em>given</em> that we know the data have been observed. To write this as an equation:<a class="footnote-reference brackets" href="#nothingnew" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight">
\[
P(h | d) = \frac{P(d,h)}{P(d)}
\]</div>
<p>However, remember what I said at the start of the last section, namely that the joint probability <span class="math notranslate nohighlight">\(P(d,h)\)</span> is calculated by multiplying the prior <span class="math notranslate nohighlight">\(P(h)\)</span> by the likelihood <span class="math notranslate nohighlight">\(P(d|h)\)</span>. In real life, the things we actually know how to write down are the priors and the likelihood, so let’s substitute those back into the equation. This gives us the following formula for the posterior probability:</p>
<div class="math notranslate nohighlight">
\[
P(h | d) = \frac{P(d|h) P(h)}{P(d)}
\]</div>
<p>And this formula, folks, is known as <strong><em>Bayes’ rule</em></strong>. It describes how a learner starts out with prior beliefs about the plausibility of different hypotheses, and tells you how those beliefs should be revised in the face of data. In the Bayesian paradigm, all statistical inference flows from this one simple rule.</p>
</section>
</section>
<section id="bayesian-hypothesis-tests">
<span id="bayesianhypothesistests"></span><h2><span class="section-number">18.2. </span>Bayesian hypothesis tests<a class="headerlink" href="#bayesian-hypothesis-tests" title="Permalink to this heading">#</a></h2>
<p>When we first discussed <span class="xref myst">hypothesis testing</span>, I described the orthodox approach. It took an entire chapter to describe, because null hypothesis testing is a very elaborate contraption that people find very hard to make sense of. In contrast, the Bayesian approach to hypothesis testing is incredibly simple. Let’s pick a setting that is closely analogous to the orthodox scenario. There are two hypotheses that we want to compare, a null hypothesis <span class="math notranslate nohighlight">\(h_0\)</span> and an alternative hypothesis <span class="math notranslate nohighlight">\(h_1\)</span>. Prior to running the experiment, we have some beliefs <span class="math notranslate nohighlight">\(P(h)\)</span> about which hypotheses are true. We run an experiment and obtain data <span class="math notranslate nohighlight">\(d\)</span>. Unlike frequentist statistics, Bayesian statistics does allow us to talk about the probability that the null hypothesis is true. Better yet, it allows us to calculate the <strong><em>posterior probability of the null hypothesis</em></strong>, using Bayes’ rule:</p>
<div class="math notranslate nohighlight">
\[
P(h_0 | d) = \frac{P(d|h_0) P(h_0)}{P(d)}
\]</div>
<p>This formula tells us exactly how much belief we should have in the null hypothesis after having observed the data <span class="math notranslate nohighlight">\(d\)</span>. Similarly, we can work out how much belief to place in the alternative hypothesis using essentially the same equation. All we do is change the subscript:</p>
<div class="math notranslate nohighlight">
\[
P(h_1 | d) = \frac{P(d|h_1) P(h_1)}{P(d)}
\]</div>
<p>It’s all so simple that I feel like an idiot even bothering to write these equations down, since all I’m doing is copying Bayes rule from the previous section.<a class="footnote-reference brackets" href="#itscomplicated" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a></p>
<section id="the-bayes-factor">
<span id="bayesfactors"></span><h3><span class="section-number">18.2.1. </span>The Bayes factor<a class="headerlink" href="#the-bayes-factor" title="Permalink to this heading">#</a></h3>
<p>In practice, most Bayesian data analysts tend not to talk in terms of the raw posterior probabilities <span class="math notranslate nohighlight">\(P(h_0|d)\)</span> and <span class="math notranslate nohighlight">\(P(h_1|d)\)</span>. Instead, we tend to talk in terms of the <strong><em>posterior odds</em></strong> ratio. Think of it like betting. Suppose, for instance, the posterior probability of the null hypothesis is 25%, and the posterior probability of the alternative is 75%. The alternative hypothesis is three times as probable as the null, so we say that the <em>odds</em> are 3:1 in favour of the alternative. Mathematically, all we have to do to calculate the posterior odds is divide one posterior probability by the other:</p>
<div class="math notranslate nohighlight">
\[
\frac{P(h_1 | d)}{P(h_0 | d)} = \frac{0.75}{0.25} = 3
\]</div>
<p>Or, to write the same thing in terms of the equations above:</p>
<div class="math notranslate nohighlight">
\[
\frac{P(h_1 | d)}{P(h_0 | d)} = \frac{P(d|h_1)}{P(d|h_0)} \times \frac{P(h_1)}{P(h_0)}
\]</div>
<p>Actually, this equation is worth expanding on. There are three different terms here that you should know. On the left hand side, we have the posterior odds, which tells you what you believe about the relative plausibilty of the null hypothesis and the alternative hypothesis <em>after</em> seeing the data. On the right hand side, we have the <strong><em>prior odds</em></strong>, which indicates what you thought <em>before</em> seeing the data. In the middle, we have the <strong><em>Bayes factor</em></strong>, which describes the amount of evidence provided by the data:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{ccccc}\displaystyle
\frac{P(h_1 | d)}{P(h_0 | d)} &amp;=&amp; \displaystyle\frac{P(d|h_1)}{P(d|h_0)} &amp;\times&amp; \displaystyle\frac{P(h_1)}{P(h_0)} \\[6pt] \\[-2pt]
\uparrow &amp;&amp; \uparrow &amp;&amp; \uparrow \\[6pt]
\mbox{Posterior odds} &amp;&amp; \mbox{Bayes factor} &amp;&amp; \mbox{Prior odds}
\end{array}
\end{split}\]</div>
<p>The Bayes factor (sometimes abbreviated as <strong><em>BF</em></strong>) has a special place in the Bayesian hypothesis testing, because it serves a similar role to the <span class="math notranslate nohighlight">\(p\)</span>-value in orthodox hypothesis testing: it quantifies the strength of evidence provided by the data, and as such it is the Bayes factor that people tend to report when running a Bayesian hypothesis test. The reason for reporting Bayes factors rather than posterior odds is that different researchers will have different priors. Some people might have a strong bias to believe the null hypothesis is true, others might have a strong bias to believe it is false. Because of this, the polite thing for an applied researcher to do is report the Bayes factor. That way, anyone reading the paper can multiply the Bayes factor by their own <em>personal</em> prior odds, and they can work out for themselves what the posterior odds would be. In any case, by convention we like to pretend that we give equal consideration to both the null hypothesis and the alternative, in which case the prior odds equals 1, and the posterior odds becomes the same as the Bayes factor.</p>
</section>
<section id="interpreting-bayes-factors">
<h3><span class="section-number">18.2.2. </span>Interpreting Bayes factors<a class="headerlink" href="#interpreting-bayes-factors" title="Permalink to this heading">#</a></h3>
<p>One of the really nice things about the Bayes factor is the numbers are inherently meaningful. If you run an experiment and you compute a Bayes factor of 4, it means that the evidence provided by your data corresponds to betting odds of 4:1 in favour of the alternative. However, there have been some attempts to quantify the standards of evidence that would be considered meaningful in a scientific context. The two most widely used are from <span id="id7">[<a class="reference internal" href="bibliography.html#id7" title="Harold Jeffreys. The Theory of Probability. Oxford, 3rd edition, 1961.">Jeffreys, 1961</a>]</span> and <span id="id8">[<a class="reference internal" href="bibliography.html#id13" title="Robert E. Kass and Adrian E. Raftery. Bayes factors. Journal of the American Statistical Association, 90:773-795, 1995.">Kass and Raftery, 1995</a>]</span>. Of the two, I tend to prefer the <span id="id9">[<a class="reference internal" href="bibliography.html#id13" title="Robert E. Kass and Adrian E. Raftery. Bayes factors. Journal of the American Statistical Association, 90:773-795, 1995.">Kass and Raftery, 1995</a>]</span> table because it’s a bit more conservative. So here it is:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Bayes factor</p></th>
<th class="head"><p>Interpretation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1 - 3</p></td>
<td><p>Negligible evidence</p></td>
</tr>
<tr class="row-odd"><td><p>3 - 20</p></td>
<td><p>Positive evidence</p></td>
</tr>
<tr class="row-even"><td><p>20 - 150</p></td>
<td><p>Strong evidence</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(&gt;\)</span> 150</p></td>
<td><p>Very strong evidence</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="why-be-a-bayesian">
<span id="whybayes"></span><h2><span class="section-number">18.3. </span>Why be a Bayesian?<a class="headerlink" href="#why-be-a-bayesian" title="Permalink to this heading">#</a></h2>
<section id="statistics-that-mean-what-you-think-they-mean">
<h3><span class="section-number">18.3.1. </span>Statistics that mean what you think they mean<a class="headerlink" href="#statistics-that-mean-what-you-think-they-mean" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="evidentiary-standards-you-can-believe">
<h2><span class="section-number">18.4. </span>Evidentiary standards you can believe<a class="headerlink" href="#evidentiary-standards-you-can-believe" title="Permalink to this heading">#</a></h2>
<section id="is-it-really-this-bad">
<h3><span class="section-number">18.4.1. </span>Is it really this bad?<a class="headerlink" href="#is-it-really-this-bad" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="bayesian-analysis-of-contingency-tables">
<span id="bayescontingency"></span><h2><span class="section-number">18.5. </span>Bayesian analysis of contingency tables<a class="headerlink" href="#bayesian-analysis-of-contingency-tables" title="Permalink to this heading">#</a></h2>
<section id="the-orthodox-text">
<h3><span class="section-number">18.5.1. </span>The orthodox text<a class="headerlink" href="#the-orthodox-text" title="Permalink to this heading">#</a></h3>
</section>
<section id="the-bayesian-test">
<h3><span class="section-number">18.5.2. </span>The Bayesian test<a class="headerlink" href="#the-bayesian-test" title="Permalink to this heading">#</a></h3>
</section>
<section id="writing-up-the-results">
<h3><span class="section-number">18.5.3. </span>Writing up the results<a class="headerlink" href="#writing-up-the-results" title="Permalink to this heading">#</a></h3>
</section>
<section id="other-sampling-plans">
<h3><span class="section-number">18.5.4. </span>Other sampling plans<a class="headerlink" href="#other-sampling-plans" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="bayesian-t-tests">
<span id="ttestbf"></span><h2><span class="section-number">18.6. </span>Bayesian <span class="math notranslate nohighlight">\(t\)</span>-tests<a class="headerlink" href="#bayesian-t-tests" title="Permalink to this heading">#</a></h2>
<section id="independent-samples-t-test">
<h3><span class="section-number">18.6.1. </span>Independent samples <span class="math notranslate nohighlight">\(t\)</span>-test<a class="headerlink" href="#independent-samples-t-test" title="Permalink to this heading">#</a></h3>
</section>
<section id="paired-samples-t-test">
<h3><span class="section-number">18.6.2. </span>Paired samples <span class="math notranslate nohighlight">\(t\)</span>-test<a class="headerlink" href="#paired-samples-t-test" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="bayesian-regression">
<span id="bayesregression"></span><h2><span class="section-number">18.7. </span>Bayesian regression<a class="headerlink" href="#bayesian-regression" title="Permalink to this heading">#</a></h2>
<section id="a-quick-refresher">
<h3><span class="section-number">18.7.1. </span>A quick refresher<a class="headerlink" href="#a-quick-refresher" title="Permalink to this heading">#</a></h3>
</section>
<section id="the-bayesian-version">
<h3><span class="section-number">18.7.2. </span>The Bayesian version<a class="headerlink" href="#the-bayesian-version" title="Permalink to this heading">#</a></h3>
</section>
<section id="finding-the-best-model">
<h3><span class="section-number">18.7.3. </span>Finding the best model<a class="headerlink" href="#finding-the-best-model" title="Permalink to this heading">#</a></h3>
</section>
<section id="extracting-bayes-factors-for-all-included-terms">
<h3><span class="section-number">18.7.4. </span>Extracting Bayes factors for all included terms<a class="headerlink" href="#extracting-bayes-factors-for-all-included-terms" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="bayesian-anova">
<span id="bayesanova"></span><h2><span class="section-number">18.8. </span>Bayesian ANOVA<a class="headerlink" href="#bayesian-anova" title="Permalink to this heading">#</a></h2>
<section id="id10">
<h3><span class="section-number">18.8.1. </span>A quick refresher<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
</section>
<section id="id11">
<h3><span class="section-number">18.8.2. </span>The Bayesian version<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
</section>
<section id="constructing-bayesian-type-ii-tests">
<h3><span class="section-number">18.8.3. </span>Constructing Bayesian Type II tests<a class="headerlink" href="#constructing-bayesian-type-ii-tests" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="summary">
<h2><span class="section-number">18.9. </span>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="adelaide" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>http://en.wikipedia.org/wiki/Climate_of_Adelaide</p>
</aside>
<aside class="footnote brackets" id="idiot" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>It’s a leap of faith, I know, but let’s run with it okay?</p>
</aside>
<aside class="footnote brackets" id="likelihood" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Um. I hate to bring this up, but some statisticians would object to me using the word “likelihood” here. The problem is that the word “likelihood” has a very specific meaning in frequentist statistics, and it’s not quite the same as what it means in Bayesian statistics. As far as I can tell, Bayesians didn’t originally have any agreed upon name for the likelihood, and so it became common practice for people to use the frequentist terminology. This wouldn’t have been a problem, except for the fact that the way that Bayesians use the word turns out to be quite different to the way frequentists do. This isn’t the place for yet another lengthy history lesson, but to put it crudely: when a Bayesian says “<em>a</em> likelihood function” they’re usually referring one of the <em>rows</em> of the table. When a frequentist says the same thing, they’re referring to the same table, but to them “<em>a</em> likelihood function” almost always refers to one of the <em>columns</em>. This distinction matters in some contexts, but it’s not important for our purposes.</p>
</aside>
<aside class="footnote brackets" id="umbrella" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">4</a><span class="fn-bracket">]</span></span>
<p>If we were being a bit more sophisticated, we could extend the example to accommodate the possibility that I’m lying about the umbrella. But let’s keep things simple, shall we?</p>
</aside>
<aside class="footnote brackets" id="nothingnew" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>You might notice that this equation is actually a restatement of the same basic rule I listed at the start of the last section. If you multiply both sides of the equation by <span class="math notranslate nohighlight">\(P(d)\)</span>, then you get <span class="math notranslate nohighlight">\(P(d) P(h| d) = P(d,h)\)</span>, which is the rule for how joint probabilities are calculated. So I’m not actually introducing any “new” rules here, I’m just using the same rule in a different way.</p>
</aside>
<aside class="footnote brackets" id="itscomplicated" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">6</a><span class="fn-bracket">]</span></span>
<p>Obviously, this is a highly simplified story. All the complexity of real life Bayesian hypothesis testing comes down to how you calculate the likelihood <span class="math notranslate nohighlight">\(P(d|h)\)</span> when the hypothesis <span class="math notranslate nohighlight">\(h\)</span> is a complex and vague thing. I’m not going to talk about those complexities in this book, but I do want to highlight that although this simple story is true as far as it goes, real life is messier than I’m able to cover in an introductory stats textbook.</p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="05.05-anova2.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">17. </span>Factorial ANOVA</p>
      </div>
    </a>
    <a class="right-next"
       href="06.02-epilogue.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">19. </span>Epilogue</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probabilistic-reasoning-by-rational-agents">18.1. Probabilistic reasoning by rational agents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#priors-what-you-believed-before">18.1.1. Priors: what you believed before</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihoods-theories-about-the-data">18.1.2. Likelihoods: theories about the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-joint-probability-of-data-and-hypothesis">18.1.3. The joint probability of data and hypothesis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#updating-beliefs-using-bayes-rule">18.1.4. Updating beliefs using Bayes’ rule</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-hypothesis-tests">18.2. Bayesian hypothesis tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayes-factor">18.2.1. The Bayes factor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-bayes-factors">18.2.2. Interpreting Bayes factors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-be-a-bayesian">18.3. Why be a Bayesian?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics-that-mean-what-you-think-they-mean">18.3.1. Statistics that mean what you think they mean</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evidentiary-standards-you-can-believe">18.4. Evidentiary standards you can believe</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-it-really-this-bad">18.4.1. Is it really this bad?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-analysis-of-contingency-tables">18.5. Bayesian analysis of contingency tables</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orthodox-text">18.5.1. The orthodox text</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-test">18.5.2. The Bayesian test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#writing-up-the-results">18.5.3. Writing up the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-sampling-plans">18.5.4. Other sampling plans</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-t-tests">18.6. Bayesian <span class="math notranslate nohighlight">\(t\)</span>-tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#independent-samples-t-test">18.6.1. Independent samples <span class="math notranslate nohighlight">\(t\)</span>-test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#paired-samples-t-test">18.6.2. Paired samples <span class="math notranslate nohighlight">\(t\)</span>-test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-regression">18.7. Bayesian regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-quick-refresher">18.7.1. A quick refresher</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bayesian-version">18.7.2. The Bayesian version</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-the-best-model">18.7.3. Finding the best model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-bayes-factors-for-all-included-terms">18.7.4. Extracting Bayes factors for all included terms</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-anova">18.8. Bayesian ANOVA</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">18.8.1. A quick refresher</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">18.8.2. The Bayesian version</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-bayesian-type-ii-tests">18.8.3. Constructing Bayesian Type II tests</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">18.9. Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Danielle Navarro and Ethan Weed
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>
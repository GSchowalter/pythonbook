{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "imperial-facing",
   "metadata": {},
   "source": [
    "(bayes)=\n",
    "# Bayesian Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f7dec85",
   "metadata": {},
   "source": [
    "> *In our reasonings concerning matter of fact, there are all imaginable degrees of assurance, from the highest certainty to the lowest species of moral evidence. A wise man, therefore, proportions his belief to the evidence.* \n",
    "-- [David Hume](http://en.wikiquote.org/wiki/David_Hume)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7d85f99",
   "metadata": {},
   "source": [
    "The ideas I've presented to you in this book describe inferential statistics from the frequentist perspective. I'm not alone in doing this. In fact, almost every textbook given to undergraduate psychology students presents the opinions of the frequentist statistician as *the* theory of inferential statistics, the one true way to do things. I have taught this way for practical reasons. The frequentist view of statistics dominated the academic field of statistics for most of the 20th century, and this dominance is even more extreme among applied scientists. It was and is current practice among psychologists to use frequentist methods, although this is changing. Because frequentist methods are ubiquitous in scientific papers, every student of statistics needs to understand those methods, otherwise they will be unable to make sense of what those papers are saying! Unfortunately -- in my opinion at least -- the current practice in psychology is often misguided, and the reliance on frequentist methods is partly to blame. In this chapter I explain why I think this, and provide an introduction to Bayesian statistics, an approach that I think is generally superior to the orthodox approach.\n",
    "\n",
    "This chapter comes in two parts. First I talk about [what Bayesian statistics are all about](basicbayes), covering the basic mathematical rules for how it works as well as an explanation for [why I think the Bayesian approach is so useful](whybayes). Afterwards, I provide a brief overview of how you can do Bayesian versions of [chi-square tests](bayescontingency), [$t$-tests](ttestbf), [regression](bayesregression)) and [ANOVA](bayesanova)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd46bb5a",
   "metadata": {},
   "source": [
    "(basicbayes)=\n",
    "## Probabilistic reasoning by rational agents\n",
    "\n",
    "From a Bayesian perspective, statistical inference is all about *belief revision*. I start out with a set of candidate hypotheses $h$ about the world. I don't know which of these hypotheses is true, but I _do_ have some beliefs about which hypotheses are plausible and which are not. When I observe the data $d$, I have to revise those beliefs. If the data are consistent with a hypothesis, my belief in that hypothesis is strengthened. If the data inconsistent with the hypothesis, my belief in that hypothesis is weakened. That's it! At the end of this section I'll give a precise description of how Bayesian reasoning works, but first I want to work through a simple example in order to introduce the key ideas. Consider the following reasoning problem:\n",
    "\n",
    "> *I'm carrying an umbrella. Do you think it will rain?*\n",
    "\n",
    "In this problem, I have presented you with a single piece of data ($d =$ I'm carrying the umbrella), and I'm asking you to tell me your beliefs about whether it's raining. You have two possible **_hypotheses_**, $h$: either it rains today or it does not. How should you solve this problem? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c40bf9e0",
   "metadata": {},
   "source": [
    "(priors)=\n",
    "### Priors: what you believed before\n",
    "\n",
    "The first thing you need to do ignore what I told you about the umbrella, and write down your pre-existing beliefs about rain. This is important: if you want to be honest about how your beliefs have been revised in the light of new evidence, then you *must* say something about what you believed before those data appeared! So, what might you believe about whether it will rain today? You probably know that I live in Australia, and that much of Australia is hot and dry. And in fact you're right: the city of Adelaide where I live has a Mediterranean climate, very similar to southern California, southern Europe or northern Africa. I'm writing this in January, and so you can assume it's the middle of summer. In fact, you might have decided to take a quick look on Wikipedia[^adelaide] and discovered that Adelaide gets an average of 4.4 days of rain across the 31 days of January. Without knowing anything else, you might conclude that the probability of January rain in Adelaide is about 15\\%, and the probability of a dry day is 85\\%. If this is really what you believe about Adelaide rainfall (and now that I've told it to you, I'm betting that this really *is* what you believe) then what I have written here is your **_prior distribution_**, written $P(h)$:\n",
    "\n",
    "[^adelaide]: http://en.wikipedia.org/wiki/Climate_of_Adelaide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec6dbb75",
   "metadata": {},
   "source": [
    "| Hypothesis | Degree of Belief |\n",
    "|------------|------------------|\n",
    "| Rainy day  | 0.15             |\n",
    "| Dry day    | 0.85             |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecbfb8f9",
   "metadata": {},
   "source": [
    "### Likelihoods: theories about the data\n",
    "\n",
    "To solve the reasoning problem, you need a theory about my behaviour. When does Dan carry an umbrella? You might guess that I'm not a complete idiot[^idiot], and I try to carry umbrellas only on rainy days. On the other hand, you also know that I have young kids, and you wouldn't be all that surprised to know that I'm pretty forgetful about this sort of thing. Let's suppose that on rainy days I remember my umbrella about 30\\% of the time (I really am awful at this). But let's say that on dry days I'm only about 5\\% likely to be carrying an umbrella. So you might write out a little table like this:\n",
    "\n",
    "[^idiot]: It's a leap of faith, I know, but let's run with it okay?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e3ee8ce",
   "metadata": {},
   "source": [
    "| Hypothesis | Umbrella | No umbrella |\n",
    "|------------|----------|-------------|\n",
    "| Rainy day  | 0.30     | 0.70        |\n",
    "| Dry day    | 0.05     | 0.95        |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1f477f7",
   "metadata": {},
   "source": [
    "It's important to remember that each cell in this table describes your beliefs about what data $d$ will be observed, *given* the truth of a particular hypothesis $h$. This \"conditional probability\" is written $P(d|h)$, which you can read as \"the probability of $d$ given $h$\". In Bayesian statistics, this is referred to as **_likelihood_** of data $d$ given hypothesis $h$.[^likelihood]\n",
    "\n",
    "[^likelihood]: Um. I hate to bring this up, but some statisticians would object to me using the word \"likelihood\" here. The problem is that the word \"likelihood\" has a very specific meaning in frequentist statistics, and it's not quite the same as what it means in Bayesian statistics. As far as I can tell, Bayesians didn't originally have any agreed upon name for the likelihood, and so it became common practice for people to use the frequentist terminology. This wouldn't have been a problem, except for the fact that the way that Bayesians use the word turns out to be quite different to the way frequentists do. This isn't the place for yet another lengthy history lesson, but to put it crudely: when a Bayesian says \"*a* likelihood function\" they're usually referring one of the *rows* of the table. When a frequentist says the same thing, they're referring to the same table, but to them \"*a* likelihood function\" almost always refers to one of the *columns*. This distinction matters in some contexts, but it's not important for our purposes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f350d58",
   "metadata": {},
   "source": [
    "### The joint probability of data and hypothesis\n",
    "\n",
    "At this point, all the elements are in place. Having written down the priors and the likelihood, you have all the information you need to do Bayesian reasoning. The question now becomes, *how* do we use this information? As it turns out, there's a very simple equation that we can use here, but it's important that you understand why we use it, so I'm going to try to build it up from more basic ideas.\n",
    "\n",
    "Let's start out with one of the rules of probability theory. I listed it in a table way back in the chapter on [probability](basicprobability), but I didn't make a big deal out of it at the time and you probably ignored it. The rule in question is the one that talks about the probability that *two* things are true. In our example, you might want to calculate the probability that today is rainy (i.e., hypothesis $h$ is true) *and* I'm carrying an umbrella (i.e., data $d$ is observed). The **_joint probability_** of the hypothesis and the data is written $P(d,h)$, and you can calculate it by multiplying the prior $P(h)$ by the likelihood $P(d|h)$. Mathematically, we say that:\n",
    "\n",
    "$$\n",
    "P(d,h) = P(d|h) P(h)\n",
    "$$\n",
    "\n",
    "So, what is the probability that today is a rainy day *and* I remember to carry an umbrella? As we discussed earlier, the prior tells us that the probability of a rainy day is 15\\%, and the likelihood tells us that the probability of me remembering my umbrella on a rainy day is 30\\%. So the probability that both of these things are true is calculated by multiplying the two:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\mbox{rainy}, \\mbox{umbrella}) & = & P(\\mbox{umbrella} | \\mbox{rainy}) \\times  P(\\mbox{rainy}) \\\\\n",
    "& = & 0.30 \\times 0.15 \\\\\n",
    "& = & 0.045\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In other words, _before being told anything about what actually happened_, you think that there is a 4.5\\% probability that today will be a rainy day and that I will remember an umbrella. However, there are of course *four* possible things that could happen, right? So let's repeat the exercise for all four. If we do that, we end up with the following table:\n",
    "\n",
    "|       | Umbrella | No-umbrella |\n",
    "|-------|----------|-------------|\n",
    "| Rainy | 0.045    | 0.105       |\n",
    "| Dry   | 0.0425   | 0.8075      |\n",
    "\n",
    "This table captures all the information about which of the four possibilities are likely. To really get the full picture, though, it helps to add the row totals and column totals. That gives us this table:\n",
    "\n",
    "|       | Umbrella | No-umbrella | Total |\n",
    "|-------|----------|-------------|-------|\n",
    "| Rainy | 0.0450   | 0.1050      | 0.15  |\n",
    "| Dry   | 0.0425   | 0.8075      | 0.85  |\n",
    "| Total | 0.0875   | 0.9125      | 1     |\n",
    "\n",
    "\n",
    "This is a very useful table, so it's worth taking a moment to think about what all these numbers are telling us. First, notice that the row sums aren't telling us anything new at all. For example, the first row tells us that if we ignore all this umbrella business, the chance that today will be a rainy day is 15\\%. That's not surprising, of course: that's our prior. The important thing isn't the number itself: rather, the important thing is that it gives us some confidence that our calculations are sensible! Now take a look at the column sums, and notice that they tell us something that we haven't explicitly stated yet. In the same way that the row sums tell us the probability of rain, the column sums tell us the probability of me carrying an umbrella. Specifically, the first column tells us that on average (i.e., ignoring whether it's a rainy day or not), the probability of me carrying an umbrella is 8.75\\%. Finally, notice that when we sum across all four logically-possible events, everything adds up to 1. In other words, what we have written down is a proper probability distribution defined over all possible combinations of data and hypothesis.\n",
    "\n",
    "\n",
    "Now, because this table is so useful, I want to make sure you understand what all the elements correspond to, and how they written:\n",
    "\n",
    "|       | Umbrella           | No-umbrella           |          |\n",
    "|-------|--------------------|-----------------------|----------|\n",
    "| Rainy | $P$(Umbrella, Rainy) | $P$(No-umbrella, Rainy) | $P$(Rainy) |\n",
    "| Dry   | $P$(Umbrella, Dry)   | $P$(No-umbrella, Dry)   | $P$(Dry)   |\n",
    "|       | $P$(Umbrella)        | $P$(No-umbrella)        |          |\n",
    "\n",
    "Finally, let's use \"proper\" statistical notation. In the rainy day problem, the data corresponds to the observation that I do or do not have an umbrella. So we'll let $d_1$ refer to the possibility that you observe me carrying an umbrella, and $d_2$ refers to you observing me not carrying one. Similarly, $h_1$ is your hypothesis that today is rainy, and $h_2$ is the hypothesis that it is not. Using this notation, the table looks like this:\n",
    "\n",
    "|       | d1       | d2       |       |\n",
    "|-------|----------|----------|-------|\n",
    "| $h_1$ | $P(h_1,d_1)$ | $P(h_1,d_2)$ | $P(h_1)$ |\n",
    "| $h_2$ | $P(h_2,d_1)$ | $P(h_2,d_2)$ | $P(h_2)$ |\n",
    "|       | $P(d_1)$     | $P(d_2)$     |          |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22fb7c61",
   "metadata": {},
   "source": [
    "### Updating beliefs using Bayes' rule\n",
    "\n",
    "The table we laid out in the last section is a very powerful tool for solving the rainy day problem, because it considers all four logical possibilities and states exactly how confident you are in each of them _before being given any data_. It's now time to consider what happens to our beliefs when we are actually given the data. In the rainy day problem, you are told that I really *am* carrying an umbrella. This is something of a surprising event: according to our table, the probability of me carrying an umbrella is only 8.75\\%. But that makes sense, right? A person carrying an umbrella on a summer day in a hot dry city is pretty unusual, and so you really weren't expecting that. Nevertheless, the problem tells you that it is true. No matter how unlikely you thought it was, you must now adjust your beliefs to accommodate the fact that you now *know* that I have an umbrella.[^umbrella] To reflect this new knowledge, our *revised* table must have the following numbers:\n",
    "\n",
    "[^umbrella]: If we were being a bit more sophisticated, we could extend the example to accommodate the possibility that I'm lying about the umbrella. But let's keep things simple, shall we?\n",
    "\n",
    "|       | Umbrella | No-umbrella |\n",
    "|-------|----------|-------------|\n",
    "| Rainy |          | 0           |\n",
    "| Dry   |          | 0           |\n",
    "| Total | 1        | 0           |\n",
    "\n",
    "In other words, the facts have eliminated any possibility of \"no umbrella\", so we have to put zeros into any cell in the table that implies that I'm not carrying an umbrella. Also, because you know for a fact that I am carrying an umbrella, so the column sum on the left must be 1 to correctly describe the fact that $P(\\mbox{umbrella})=1$.\n",
    "\n",
    "What two numbers should we put in the empty cells? Again, let's not worry about the maths, and instead think about our intuitions. When we wrote out our table the first time, it turned out that those two cells had almost identical numbers, right? We worked out that the joint probability of \"rain and umbrella\" was 4.5\\%, and the joint probability of \"dry and umbrella\" was 4.25\\%. In other words, before I told you that I am in fact carrying an umbrella, you'd have said that these two events were almost identical in probability, yes? But notice that *both* of these possibilities are consistent with the fact that I actually am carrying an umbrella. From the perspective of these two possibilities, very little has changed. I hope you'd agree that it's *still* true that these two possibilities are equally plausible. So what we expect to see in our final table is some numbers that preserve the fact that \"rain and umbrella\" is *slightly* more plausible than \"dry and umbrella\", while still ensuring that numbers in the table add up. Something like this, perhaps?\n",
    "\n",
    "|          | Umbrella    | No-umbrella    |\n",
    "|----------|-------------|----------------|\n",
    "| Rainy    | 0.514       | 0              |\n",
    "| Dry      | 0.486       | 0              |\n",
    "| Total    | 1           | 0              |\n",
    "\n",
    "What this table is telling you is that, after being told that I'm carrying an umbrella, you believe that there's a 51.4\\% chance that today will be a rainy day, and a 48.6\\% chance that it won't. That's the answer to our problem! The **_posterior probability_** of rain $P(h|d)$ given that I am carrying an umbrella is 51.4\\%\n",
    "\n",
    "How did I calculate these numbers? You can probably guess. To work out that there was a 0.514 probability of \"rain\", all I did was take the 0.045 probability of \"rain and umbrella\" and divide it by the 0.0875 chance of \"umbrella\". This produces a table that satisfies our need to have everything sum to 1, and our need not to interfere with the relative plausibility of the two events that are actually consistent with the data. To say the same thing using fancy statistical jargon, what I've done here is divide the joint probability of the hypothesis and the data $P(d,h)$ by the **_marginal probability_** of the data $P(d)$, and this is what gives us the posterior probability of the hypothesis *given* that we know the data have been observed. To write this as an equation:[^nothingnew]\n",
    "    \n",
    "[^nothingnew]: You might notice that this equation is actually a restatement of the same basic rule I listed at the start of the last section. If you multiply both sides of the equation by $P(d)$, then you get $P(d) P(h| d) = P(d,h)$, which is the rule for how joint probabilities are calculated. So I'm not actually introducing any \"new\" rules here, I'm just using the same rule in a different way.\n",
    "\n",
    "$$\n",
    "P(h | d) = \\frac{P(d,h)}{P(d)}\n",
    "$$\n",
    "\n",
    "However, remember what I said at the start of the last section, namely that the joint probability $P(d,h)$ is calculated by multiplying the prior $P(h)$ by the likelihood $P(d|h)$. In real life, the things we actually know how to write down are the priors and the likelihood, so let's substitute those back into the equation. This gives us the following formula for the posterior probability:\n",
    "\n",
    "$$\n",
    "P(h | d) = \\frac{P(d|h) P(h)}{P(d)}\n",
    "$$\n",
    "\n",
    "And this formula, folks, is known as **_Bayes' rule_**. It describes how a learner starts out with prior beliefs about the plausibility of different hypotheses, and tells you how those beliefs should be revised in the face of data. In the Bayesian paradigm, all statistical inference flows from this one simple rule."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "020e5bfa",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e55f10a",
   "metadata": {},
   "source": [
    "(bayesianhypothesistests)=\n",
    "## Bayesian hypothesis tests\n",
    "\n",
    "When we first discussed [hypothesis testing](hypothesistesting), I described the orthodox approach. It took an entire chapter to describe, because null hypothesis testing is a very elaborate contraption that people find very hard to make sense of. In contrast, the Bayesian approach to hypothesis testing is incredibly simple. Let's pick a setting that is closely analogous to the orthodox scenario. There are two hypotheses that we want to compare, a null hypothesis $h_0$ and an alternative hypothesis $h_1$. Prior to running the experiment, we have some beliefs $P(h)$ about which hypotheses are true. We run an experiment and obtain data $d$. Unlike frequentist statistics, Bayesian statistics does allow us to talk about the probability that the null hypothesis is true. Better yet, it allows us to calculate the **_posterior probability of the null hypothesis_**, using Bayes' rule:\n",
    "\n",
    "$$\n",
    "P(h_0 | d) = \\frac{P(d|h_0) P(h_0)}{P(d)}\n",
    "$$\n",
    "\n",
    "This formula tells us exactly how much belief we should have in the null hypothesis after having observed the data $d$. Similarly, we can work out how much belief to place in the alternative hypothesis using essentially the same equation. All we do is change the subscript:\n",
    "\n",
    "$$\n",
    "P(h_1 | d) = \\frac{P(d|h_1) P(h_1)}{P(d)}\n",
    "$$\n",
    "\n",
    "It's all so simple that I feel like an idiot even bothering to write these equations down, since all I'm doing is copying Bayes rule from the previous section.[^itscomplicated]\n",
    "\n",
    "[^itscomplicated]: Obviously, this is a highly simplified story. All the complexity of real life Bayesian hypothesis testing comes down to how you calculate the likelihood $P(d|h)$ when the hypothesis $h$ is a complex and vague thing. I'm not going to talk about those complexities in this book, but I do want to highlight that although this simple story is true as far as it goes, real life is messier than I'm able to cover in an introductory stats textbook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d997c010",
   "metadata": {},
   "source": [
    "(bayesfactors)=\n",
    "### The Bayes factor\n",
    "\n",
    "In practice, most Bayesian data analysts tend not to talk in terms of the raw posterior probabilities $P(h_0|d)$ and $P(h_1|d)$. Instead, we tend to talk in terms of the **_posterior odds_** ratio. Think of it like betting. Suppose, for instance, the posterior probability of the null hypothesis is 25\\%, and the posterior probability of the alternative is 75\\%. The alternative hypothesis is three times as probable as the null, so we say that the *odds* are 3:1 in favour of the alternative. Mathematically, all we have to do to calculate the posterior odds is divide one posterior probability by the other:\n",
    "\n",
    "$$\n",
    "\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{0.75}{0.25} = 3\n",
    "$$\n",
    "\n",
    "Or, to write the same thing in terms of the equations above:\n",
    "\n",
    "$$\n",
    "\\frac{P(h_1 | d)}{P(h_0 | d)} = \\frac{P(d|h_1)}{P(d|h_0)} \\times \\frac{P(h_1)}{P(h_0)}\n",
    "$$\n",
    "\n",
    "Actually, this equation is worth expanding on. There are three different terms here that you should know. On the left hand side, we have the posterior odds, which tells you what you believe about the relative plausibilty of the null hypothesis and the alternative hypothesis *after* seeing the data. On the right hand side, we have the **_prior odds_**, which indicates what you thought *before* seeing the data. In the middle, we have the **_Bayes factor_**, which describes the amount of evidence provided by the data:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccc}\\displaystyle\n",
    "\\frac{P(h_1 | d)}{P(h_0 | d)} &=& \\displaystyle\\frac{P(d|h_1)}{P(d|h_0)} &\\times& \\displaystyle\\frac{P(h_1)}{P(h_0)} \\\\[6pt] \\\\[-2pt]\n",
    "\\uparrow && \\uparrow && \\uparrow \\\\[6pt]\n",
    "\\mbox{Posterior odds} && \\mbox{Bayes factor} && \\mbox{Prior odds}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The Bayes factor (sometimes abbreviated as **_BF_**) has a special place in the Bayesian hypothesis testing, because it serves a similar role to the $p$-value in orthodox hypothesis testing: it quantifies the strength of evidence provided by the data, and as such it is the Bayes factor that people tend to report when running a Bayesian hypothesis test. The reason for reporting Bayes factors rather than posterior odds is that different researchers will have different priors. Some people might have a strong bias to believe the null hypothesis is true, others might have a strong bias to believe it is false. Because of this, the polite thing for an applied researcher to do is report the Bayes factor. That way, anyone reading the paper can multiply the Bayes factor by their own *personal* prior odds, and they can work out for themselves what the posterior odds would be. In any case, by convention we like to pretend that we give equal consideration to both the null hypothesis and the alternative, in which case the prior odds equals 1, and the posterior odds becomes the same as the Bayes factor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d934836",
   "metadata": {},
   "source": [
    "### Interpreting Bayes factors\n",
    "\n",
    "One of the really nice things about the Bayes factor is the numbers are inherently meaningful. If you run an experiment and you compute a Bayes factor of 4, it means that the evidence provided by your data corresponds to betting odds of 4:1 in favour of the alternative. However, there have been some attempts to quantify the standards of evidence that would be considered meaningful in a scientific context. The two most widely used are from {cite:ts}`Jeffreys1961` and {cite:ts}`Kass1995`. Of the two, I tend to prefer the {cite:ts}`Kass1995` table because it's a bit more conservative. So here it is:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d9fe758",
   "metadata": {},
   "source": [
    "| Bayes factor | Interpretation       |\n",
    "|--------------|----------------------|\n",
    "| 1 - 3        | Negligible evidence  |\n",
    "| 3 - 20       | Positive evidence    |\n",
    "| 20 - 150     | Strong evidence      |\n",
    "| $>$ 150       | Very strong evidence |\n",
    "\n",
    "\n",
    "And to be perfectly honest, I think that even the Kass and Raftery standards are being a bit charitable. If it were up to me, I'd have called the \"positive evidence\" category \"weak evidence\". To me, anything in the range 3:1 to 20:1 is \"weak\" or \"modest\" evidence at best. But there are no hard and fast rules here: what counts as strong or weak evidence depends entirely on how conservative you are, and upon the standards that your community insists upon before it is willing to label a finding as \"true\". \n",
    "\n",
    "In any case, note that all the numbers listed above make sense if the Bayes factor is greater than 1 (i.e., the evidence favours the alternative hypothesis). However, one big practical advantage of the Bayesian approach relative to the orthodox approach is that it also allows you to quantify evidence *for* the null. When that happens, the Bayes factor will be less than 1. You can choose to report a Bayes factor less than 1, but to be honest I find it confusing. For example, suppose that the likelihood of the data under the null hypothesis $P(d|h_0)$ is equal to 0.2, and the corresponding likelihood $P(d|h_1)$ under the alternative hypothesis is 0.1. Using the equations given above,  Bayes factor here would be:\n",
    "\n",
    "$$ \n",
    "\\mbox{BF} = \\frac{P(d|h_1)}{P(d|h_0)} = \\frac{0.1}{0.2} = 0.5\n",
    "$$\n",
    "\n",
    "Read literally, this result tells is that the evidence in favour of the alternative is 0.5 to 1. I find this hard to understand. To me, it makes  a lot more sense to turn the equation \"upside down\", and report the amount op evidence in favour of the *null*. In other words, what we calculate is this:\n",
    "\n",
    "$$ \n",
    "\\mbox{BF}^\\prime = \\frac{P(d|h_0)}{P(d|h_1)} = \\frac{0.2}{0.1} = 2\n",
    "$$\n",
    "\n",
    "And what we would report is a Bayes factor of 2:1 in favour of the null. Much easier to understand, and you can interpret this using the table above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06b02e71",
   "metadata": {},
   "source": [
    "(whybayes)=\n",
    "## Why be a Bayesian?\n",
    "\n",
    "Up to this point I've focused exclusively on the logic underpinning Bayesian statistics. We've talked about the idea of \"probability as a degree of belief\", and what it implies about how a rational agent should reason about the world. The question that you have to answer for yourself is this: how do *you* want to do your statistics? Do you want to be an orthodox statistician, relying on sampling distributions and $p$-values to guide your decisions? Or do you want to be a Bayesian, relying on Bayes factors and the rules for rational belief revision? And to be perfectly honest, I can't answer this question for you. Ultimately it depends on what you think is right. It's your call, and your call alone. That being said, I can talk a little about why *I* prefer the Bayesian approach. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6170c12d",
   "metadata": {},
   "source": [
    "### Statistics that mean what you think they mean\n",
    "\n",
    "> *You keep using that word. I do not think it means what you think it means*  \n",
    "-- Inigo Montoya, The Princess Bride [^inigo]\n",
    "\n",
    "\n",
    "To me, one of the biggest advantages to the Bayesian approach is that it answers the right questions. Within the Bayesian framework, it is perfectly sensible and allowable to refer to \"the probability that a hypothesis is true\". You can even try to calculate this probability. Ultimately, isn't that what you *want* your statistical tests to tell you? To an actual human being, this would seem to be the whole *point* of doing statistics: to determine what is true and what isn't. Any time that you aren't exactly sure about what the truth is, you should use the language of probability theory to say things like \"there is an 80\\% chance that Theory A is true, but a 20\\% chance that Theory B is true instead\". \n",
    "\n",
    "This seems so obvious to a human, yet it is explicitly forbidden within the orthodox framework. To a frequentist, such statements are a nonsense because \"the theory is true\" is not a repeatable event. A theory is true or it is not, and no probabilistic statements are allowed, no matter how much you might want to make them. There's a reason why, back when we talked about [$p$-values](pvalue), I repeatedly warned you *not* to interpret the $p$-value as the probability that the null hypothesis is true. There's a reason why almost every textbook on statstics is forced to repeat that warning. It's because people desperately *want* that to be the correct interpretation. Frequentist dogma notwithstanding, a lifetime of experience of teaching undergraduates and of doing data analysis on a daily basis suggests to me that most actual humans think that \"the probability that the hypothesis is true\" is not only meaningful, it's the thing we care *most* about. It's such an appealing idea that even trained statisticians fall prey to the mistake of trying to interpret a $p$-value this way. For example, here is a quote from an official Newspoll report in 2013, explaining how to interpret their (frequentist) data analysis:[^newspoll]\n",
    "\n",
    "[^newspoll]: http://about.abc.net.au/reports-publications/appreciation-survey-summary-report-2013/\n",
    "\n",
    "> Throughout the report, where relevant, statistically significant changes have been noted. All significance tests have been based on the 95 percent level of confidence. **This means that if a change is noted as being statistically significant, there is a 95 percent probability that a real change has occurred**, and is not simply due to chance variation. (emphasis added)\n",
    "\n",
    "Nope! That's *not* what $p<.05$ means. That's *not* what 95\\% confidence means to a frequentist statistician. The bolded section is just plain wrong. Orthodox methods cannot tell you that \"there is a 95\\% chance that a real change has occurred\", because this is not the kind of event to which frequentist probabilities may be assigned. To an ideological frequentist, this sentence should be meaningless. Even if you're a more pragmatic frequentist, it's still the wrong definition of a $p$-value. It is simply not an allowed or correct thing to say if you want to rely on orthodox statistical tools. \n",
    "\n",
    "On the other hand, let's suppose you are a Bayesian. Although the bolded passage is the wrong definition of a $p$-value, it's pretty much exactly what a Bayesian means when they say that the posterior probability of the alternative hypothesis is greater than 95\\%. And here's the thing. If the Bayesian posterior is actually thing you *want* to report, why are you even trying to use orthodox methods? If you want to make Bayesian claims, all you have to do is be a Bayesian and use Bayesian tools. \n",
    "\n",
    "Speaking for myself, I found this to be a the most liberating thing about switching to the Bayesian view. Once you've made the jump, you no longer have to wrap your head around counterinuitive definitions of $p$-values. You don't have to bother remembering why you can't say that you're 95\\% confident that the true mean lies within some interval. All you have to do is be honest about what you believed before you ran the study, and then report what you learned from doing it. Sounds nice, doesn't it? To me, this is the big promise of the Bayesian approach: you do the analysis you really want to do, and express what you really believe the data are telling you.\n",
    "\n",
    "[^inigo]: http://www.imdb.com/title/tt0093779/quotes. I should note in passing that I'm not the first person to use this quote to complain about frequentist methods. Rich Morey and colleagues had the idea first. I'm shamelessly stealing it because it's such an awesome pull quote to use in this context and I refuse to miss any opportunity to quote *The Princess Bride*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86aea727",
   "metadata": {},
   "source": [
    "> *If [$p$] is below .02 it is strongly indicated that the [null] hypothesis fails to account for the whole of the facts. We shall not often be astray if we draw a conventional line at .05 and consider that [smaller values of $p$] indicate a real discrepancy.*  \n",
    "-- Sir Ronald {cite:ts}`Fisher1925`\n",
    "\n",
    "\n",
    "Consider the quote above by Sir Ronald Fisher, one of the founders of what has become the orthodox approach to statistics. If anyone has ever been entitled to express an opinion about the intended function of $p$-values, it's Fisher. In this passage, taken from his classic guide *Statistical Methods for Research Workers*, he's pretty clear about what it means to reject a null hypothesis at $p<.05$. In his opinion, if we take $p<.05$ to mean there is \"a real effect\", then \"we shall not often be astray\". This view is hardly unusual: in my experience, most practitioners express views very similar to Fisher's. In essence, the $p<.05$ convention is assumed to represent a fairly stringent evidentiary standard.\n",
    "\n",
    "Well, how true is that? One way to approach this question is to try to convert $p$-values to Bayes factors, and see how the two compare. It's not an easy thing to do because a $p$-value is a fundamentally different kind of calculation to a Bayes factor, and they don't measure the same thing. However, there have been some attempts to work out the relationship between the two, and it's somewhat surprising. For example, @Johnson2013 presents a pretty compelling case that (for $t$-tests at least) the  $p<.05$ threshold corresponds roughly to a Bayes factor of somewhere between 3:1 and 5:1 in favour of the alternative. If that's right, then Fisher's claim is a bit of a stretch. Let's suppose that the null hypothesis is true about half the time (i.e., the prior probability of $H_0$ is 0.5), and we use those numbers to work out the posterior probability of the null hypothesis given that it has been rejected at $p<.05$. Using the data from @Johnson2013, we see that if you reject the null at $p<.05$, you'll be correct about 80\\% of the time. I don't know about you, but in my opinion an evidentiary standard that ensures you'll be wrong on 20\\% of your decisions isn't good enough. The fact remains that, quite contrary to Fisher's claim, if you reject at $p<.05$ you shall quite often go astray. It's not a very stringent evidentiary threshold at all. \n",
    "\n",
    "\n",
    "## The $p$-value is a lie.\n",
    "\n",
    "\n",
    "> *The cake is a lie.*  \n",
    "*The cake is a lie.*  \n",
    "*The cake is a lie.*  \n",
    "*The cake is a lie.*  \n",
    "-- Portal^[http://knowyourmeme.com/memes/the-cake-is-a-lie]\n",
    "\n",
    "\n",
    "Okay, at this point you might be thinking that the real problem is not with orthodox statistics, just the $p<.05$ standard. In one sense, that's true. The recommendation that @Johnson2013 gives is not that \"everyone must be a Bayesian now\". Instead, the suggestion is that it would be wiser to shift the conventional standard to something like a $p<.01$ level. That's not an unreasonable view to take, but in my view the problem is a little more severe than that. In my opinion, there's a fairly big problem built into the way most (but not all) orthodox hypothesis tests are constructed. They are grossly naive about how humans actually do research, and because of this most $p$-values are wrong. \n",
    "\n",
    "Sounds like an absurd claim, right? Well, consider the following scenario. You've come up with a really exciting research hypothesis and you design a study to test it. You're very diligent, so you run a power analysis to work out what your sample size should be, and you run the study. You run your hypothesis test and out pops a $p$-value of 0.072. Really bloody annoying, right? \n",
    "\n",
    "What should you do? Here are some possibilities:\n",
    "\n",
    "\n",
    "1. You conclude that there is no effect, and try to publish it as a null result\n",
    "1. You guess that there might be an effect, and try to publish it as a \"borderline significant\" result\n",
    "1. You give up and try a new study\n",
    "1. You collect some more data to see if the $p$ value goes up or (preferably!) drops below the \"magic\" criterion of $p<.05$\n",
    "\n",
    "\n",
    "Which would *you* choose? Before reading any further, I urge you to take some time to think about it. Be honest with yourself. But don't stress about it too much, because you're screwed no matter what you choose. Based on my own experiences as an author, reviewer and editor, as well as stories I've heard from others, here's what will happen in each case:\n",
    "\n",
    "\n",
    "- Let's start with option 1. If you try to publish it as a null result, the paper will struggle to be published. Some reviewers will think that $p=.072$ is not really a null result. They'll argue it's borderline significant. Other reviewers will agree it's a null result, but will claim that even though some null results *are* publishable, yours isn't. One or two reviewers might even be on your side, but you'll be fighting an uphill battle to get it through.\n",
    "\n",
    "- Okay, let's think about option number 2. Suppose you try to publish it as a borderline significant result. Some reviewers will claim that it's a null result and should not be published. Others will claim that the evidence is ambiguous, and that you should collect more data until you get a clear significant result. Again, the publication process does not favour you.\n",
    "\n",
    "- Given the difficulties in publishing an \"ambiguous\" result like $p=.072$, option number 3 might seem tempting: give up and do something else. But that's a recipe for career suicide. If you give up and try a new project else every time you find yourself faced with ambiguity, your work will never be published. And if you're in academia without a publication record you can lose your job. So that option is out.\n",
    "\n",
    "- It looks like you're stuck with option 4. You don't have conclusive results, so you decide to collect some more data and re-run the analysis. Seems sensible, but unfortunately for you, if you do this all of your $p$-values are now incorrect. *All* of them. Not just the $p$-values that you calculated for *this* study. All of them. All the $p$-values you calculated in the past and all the $p$-values you will calculate in the future. Fortunately, no-one will notice. You'll get published, and you'll have lied.\n",
    "\n",
    "Wait, what? How can that last part be true? I mean, it sounds like a perfectly reasonable strategy doesn't it? You collected some data, the results weren't conclusive, so now what you want to do is collect more data until the the results *are* conclusive. What's wrong with that?\n",
    "\n",
    "Honestly, there's nothing wrong with it. It's a reasonable, sensible and rational thing to do. In real life, this is exactly what every researcher does. Unfortunately, the theory of null hypothesis testing as I described it in Chapter \\@ref(hypothesistesting) *forbids* you from doing this.^[In the interests of being completely honest,  I should acknowledge that not all orthodox statistical tests that rely on this silly assumption. There are a number of *sequential analysis* tools that are sometimes used in clinical trials and the like. These methods are built on the assumption that data are analysed as they arrive, and these tests aren't horribly broken in the way I'm complaining about here. However, sequential analysis methods are constructed in a very different fashion to the \"standard\" version of null hypothesis testing. They don't make it into any introductory textbooks, and they're not very widely used in the psychological literature. The concern I'm raising here is valid for every single orthodox test I've presented so far, and for almost every test I've seen reported in the papers I read.] The reason is that the theory assumes that the experiment is finished and all the data are in. And because it assumes the experiment is over, it only considers *two* possible decisions. If you're using the conventional $p<.05$ threshold, those decisions are:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ce4a648",
   "metadata": {},
   "source": [
    "## Evidentiary standards you can believe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe43f6aa",
   "metadata": {},
   "source": [
    "### Is it really this bad?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93c3616d",
   "metadata": {},
   "source": [
    "(bayescontingency)=\n",
    "## Bayesian analysis of contingency tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98b14380",
   "metadata": {},
   "source": [
    "### The orthodox text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "176b3d85",
   "metadata": {},
   "source": [
    "### The Bayesian test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36fc4cc7",
   "metadata": {},
   "source": [
    "### Writing up the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36db1a47",
   "metadata": {},
   "source": [
    "### Other sampling plans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "713ef507",
   "metadata": {},
   "source": [
    "(ttestbf)=\n",
    "## Bayesian $t$-tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06e30ebb",
   "metadata": {},
   "source": [
    "### Independent samples $t$-test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3b2f313",
   "metadata": {},
   "source": [
    "### Paired samples $t$-test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5025fdeb",
   "metadata": {},
   "source": [
    "(bayesregression)=\n",
    "## Bayesian regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec1dca42",
   "metadata": {},
   "source": [
    "### A quick refresher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dc9bbe2",
   "metadata": {},
   "source": [
    "### The Bayesian version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a8b91de",
   "metadata": {},
   "source": [
    "### Finding the best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fe83094",
   "metadata": {},
   "source": [
    "### Extracting Bayes factors for all included terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "099e79e8",
   "metadata": {},
   "source": [
    "(bayesanova)=\n",
    "## Bayesian ANOVA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a93bb9",
   "metadata": {},
   "source": [
    "### A quick refresher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43ca2015",
   "metadata": {},
   "source": [
    "### The Bayesian version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dffe7b0",
   "metadata": {},
   "source": [
    "### Constructing Bayesian Type II tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c826eaac",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78e73888",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
